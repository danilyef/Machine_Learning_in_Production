{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab import Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet data into pandas DataFrame\n",
    "df = pd.read_parquet('/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/homework_3/pr4/synthetic_reviews.parquet')\n",
    "\n",
    "raw_texts, labels = df[\"Email\"].values, df[\"Category\"].values\n",
    "num_classes = len(set(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transformer = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "text_embeddings = transformer.encode(raw_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1415: RuntimeWarning: Number of classes in training fold (8) does not match total number of classes (9). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=400)\n",
    "pred_probs = cross_val_predict(model, text_embeddings, labels, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"texts\": raw_texts, \"labels\": labels}\n",
    "lab = Datalab(data_dict, label_name=\"labels\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information: num_examples: 95, num_classes: 9\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "     issue_type  num_issues\n",
      " near_duplicate           6\n",
      "          label           4\n",
      "        outlier           1\n",
      "        non_iid           1\n",
      "class_imbalance           1\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 6\n",
      "Overall dataset quality in terms of this issue: 0.5928\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "88                     True              0.000000                [65]                      0.000000\n",
      "65                     True              0.000000                [88]                      0.000000\n",
      "1                      True              0.049541                [79]                      0.011727\n",
      "79                     True              0.049541                 [1]                      0.011727\n",
      "94                     True              0.067793                [60]                      0.016202\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 4\n",
      "Overall dataset quality in terms of this issue: 0.7895\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_label_issue  label_score  given_label  predicted_label\n",
      "63           False     0.000000            9                6\n",
      "38           False     0.017116            3                6\n",
      "25           False     0.017385            3                2\n",
      "92            True     0.095429            2                6\n",
      "77           False     0.131557            7                5\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.3703\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_outlier_issue  outlier_score\n",
      "16              True       0.180302\n",
      "24             False       0.198092\n",
      "83             False       0.215768\n",
      "9              False       0.227210\n",
      "61             False       0.230044\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0252\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_non_iid_issue  non_iid_score\n",
      "92              True       0.731450\n",
      "77             False       0.735458\n",
      "74             False       0.738131\n",
      "90             False       0.754504\n",
      "5              False       0.755526\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.02517227816458212\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0105\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_class_imbalance_issue  class_imbalance_score  given_label\n",
      "63                      True               0.010526            9\n",
      "0                      False               1.000000            1\n",
      "68                     False               1.000000            5\n",
      "67                     False               1.000000            8\n",
      "66                     False               1.000000            6\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: 9\n"
     ]
    }
   ],
   "source": [
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "identified_label_issues = label_issues[label_issues[\"is_label_issue\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sehr geehrter Kundenservice, ich möchte mein I...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ich habe den Service von Ihnen bereits gekündi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Guten Tag, können Sie mir bitte die Zahlungsei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Guten Tag, ich habe ein Problem mit der letzte...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Email  Category\n",
       "3   Sehr geehrter Kundenservice, ich möchte mein I...         4\n",
       "21  Ich habe den Service von Ihnen bereits gekündi...         4\n",
       "47  Guten Tag, können Sie mir bitte die Zahlungsei...         2\n",
       "92  Guten Tag, ich habe ein Problem mit der letzte...         2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>0.14025</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_label_issue  label_score  given_label  predicted_label\n",
       "16           False      0.14025            1                6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_issues = lab.get_issues(\"outlier\")\n",
    "label_issues[outlier_issues[\"is_outlier_issue\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Email</th>\n",
       "      <th>Original_Category</th>\n",
       "      <th>Duplicate_Email</th>\n",
       "      <th>Duplicate_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte um d...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte eine...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guten Tag, ich möchte meinen Vertrag schnellst...</td>\n",
       "      <td>4</td>\n",
       "      <td>Guten Tag, ich möchte den Vertrag so schnell w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte eine...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte um d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guten Tag, ich möchte den Vertrag so schnell w...</td>\n",
       "      <td>4</td>\n",
       "      <td>Guten Tag, ich möchte meinen Vertrag schnellst...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Original_Email  Original_Category  \\\n",
       "0  Sehr geehrte Damen und Herren, ich möchte um d...                  8   \n",
       "1  Guten Tag, ich möchte meinen Vertrag schnellst...                  4   \n",
       "2  Guten Tag, ich möchte meine Bestellung stornie...                  4   \n",
       "3  Sehr geehrte Damen und Herren, ich möchte eine...                  8   \n",
       "4  Guten Tag, ich möchte meine Bestellung stornie...                  4   \n",
       "5  Guten Tag, ich möchte den Vertrag so schnell w...                  4   \n",
       "\n",
       "                                     Duplicate_Email  Duplicate_Category  \n",
       "0  Sehr geehrte Damen und Herren, ich möchte eine...                   8  \n",
       "1  Guten Tag, ich möchte den Vertrag so schnell w...                   4  \n",
       "2  Guten Tag, ich möchte meine Bestellung stornie...                   4  \n",
       "3  Sehr geehrte Damen und Herren, ich möchte um d...                   8  \n",
       "4  Guten Tag, ich möchte meine Bestellung stornie...                   4  \n",
       "5  Guten Tag, ich möchte meinen Vertrag schnellst...                   4  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_issues = lab.get_issues(\"near_duplicate\")\n",
    "duplicate_issues_idx = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"] == True].index.to_numpy()\n",
    "duplicate_issues_idx_2 = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"] == True].near_duplicate_sets.to_numpy()\n",
    "\n",
    "duplicate_issues_idx_2 = [item for sublist in duplicate_issues_idx_2 for item in sublist]\n",
    "\n",
    "duplicates_df = pd.concat([df.loc[duplicate_issues_idx].reset_index(drop=True), \n",
    "                           df.loc[duplicate_issues_idx_2].reset_index(drop=True)], axis=1)\n",
    "duplicates_df.columns = ['Original_Email', 'Original_Category', 'Duplicate_Email', 'Duplicate_Category']\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sehr geehrte Damen und Herren, ich möchte um die Kopie meines Vertrags bitten.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sehr geehrte Damen und Herren, ich möchte eine Kopie meines Vertrags anfordern.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[79,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte um d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Guten Tag, ich möchte meinen Vertrag schnellst...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Sehr geehrte Damen und Herren, ich möchte eine...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Guten Tag, ich möchte meine Bestellung stornie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Guten Tag, ich möchte den Vertrag so schnell w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Email  Category\n",
       "1   Sehr geehrte Damen und Herren, ich möchte um d...         8\n",
       "60  Guten Tag, ich möchte meinen Vertrag schnellst...         4\n",
       "65  Guten Tag, ich möchte meine Bestellung stornie...         4\n",
       "79  Sehr geehrte Damen und Herren, ich möchte eine...         8\n",
       "88  Guten Tag, ich möchte meine Bestellung stornie...         4\n",
       "94  Guten Tag, ich möchte den Vertrag so schnell w...         4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[duplicate_issues_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 60, 65, 79, 88, 94])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_issues_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/cleanlab/filter.py:904: UserWarning: May not flag all label issues in class: 0, it has too few examples (see `min_examples_per_class` argument)\n",
      "  warnings.warn(\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/cleanlab/filter.py:904: UserWarning: May not flag all label issues in class: 8, it has too few examples (see `min_examples_per_class` argument)\n",
      "  warnings.warn(\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/cleanlab/filter.py:904: UserWarning: May not flag all label issues in class: 2, it has too few examples (see `min_examples_per_class` argument)\n",
      "  warnings.warn(\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/cleanlab/filter.py:904: UserWarning: May not flag all label issues in class: 6, it has too few examples (see `min_examples_per_class` argument)\n",
      "  warnings.warn(\n",
      "/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/env/lib/python3.9/site-packages/cleanlab/filter.py:904: UserWarning: May not flag all label issues in class: 7, it has too few examples (see `min_examples_per_class` argument)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab import Datalab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read parquet data into pandas DataFrame\n",
    "df = pd.read_parquet('/Users/daniil.yefimov/Desktop/Github/machine_learning_in_production/homework_3/pr4/synthetic_reviews.parquet')\n",
    "\n",
    "raw_texts, labels = df[\"Email\"].values, df[\"Category\"].values\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "\n",
    "transformer = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "text_embeddings = transformer.encode(raw_texts)\n",
    "\n",
    "model = LogisticRegression(max_iter=400)\n",
    "pred_probs = cross_val_predict(model, text_embeddings, labels, method=\"predict_proba\")\n",
    "\n",
    "data_dict = {\"texts\": raw_texts, \"labels\": labels}\n",
    "lab = Datalab(data_dict, label_name=\"labels\",verbosity = 0)\n",
    "lab.find_issues(pred_probs=pred_probs, features=text_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Email  Category\n",
      "3   Sehr geehrter Kundenservice, ich möchte mein I...         4\n",
      "21  Ich habe den Service von Ihnen bereits gekündi...         4\n",
      "47  Guten Tag, können Sie mir bitte die Zahlungsei...         2\n",
      "92  Guten Tag, ich habe ein Problem mit der letzte...         2\n",
      "                                                Email  Category\n",
      "16  Ich habe Fragen zu Ihrer Geschäftslösung und w...         1\n",
      "                                      Original_Email  Original_Category  \\\n",
      "0  Sehr geehrte Damen und Herren, ich möchte um d...                  8   \n",
      "1  Guten Tag, ich möchte meinen Vertrag schnellst...                  4   \n",
      "2  Guten Tag, ich möchte meine Bestellung stornie...                  4   \n",
      "3  Sehr geehrte Damen und Herren, ich möchte eine...                  8   \n",
      "4  Guten Tag, ich möchte meine Bestellung stornie...                  4   \n",
      "5  Guten Tag, ich möchte den Vertrag so schnell w...                  4   \n",
      "\n",
      "                                     Duplicate_Email  Duplicate_Category  \n",
      "0  Sehr geehrte Damen und Herren, ich möchte eine...                   8  \n",
      "1  Guten Tag, ich möchte den Vertrag so schnell w...                   4  \n",
      "2  Guten Tag, ich möchte meine Bestellung stornie...                   4  \n",
      "3  Sehr geehrte Damen und Herren, ich möchte um d...                   8  \n",
      "4  Guten Tag, ich möchte meine Bestellung stornie...                   4  \n",
      "5  Guten Tag, ich möchte meinen Vertrag schnellst...                   4  \n"
     ]
    }
   ],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues_idx = label_issues[label_issues[\"is_label_issue\"] == True].index.to_numpy()\n",
    "print(df.iloc[label_issues_idx])\n",
    "\n",
    "outlier_issues = lab.get_issues(\"outlier\")\n",
    "outlier_issues_idx = outlier_issues[outlier_issues[\"is_outlier_issue\"] == True].index.to_numpy()\n",
    "print(df.iloc[outlier_issues_idx])\n",
    "\n",
    "\n",
    "\n",
    "duplicate_issues = lab.get_issues(\"near_duplicate\")\n",
    "duplicate_issues_idx = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"] == True].index.to_numpy()\n",
    "duplicate_issues_idx_2 = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"] == True].near_duplicate_sets.to_numpy()\n",
    "\n",
    "duplicate_issues_idx_2 = [item for sublist in duplicate_issues_idx_2 for item in sublist]\n",
    "\n",
    "duplicates_df = pd.concat([df.loc[duplicate_issues_idx].reset_index(drop=True), \n",
    "                           df.loc[duplicate_issues_idx_2].reset_index(drop=True)], axis=1)\n",
    "duplicates_df.columns = ['Original_Email', 'Original_Category', 'Duplicate_Email', 'Duplicate_Category']\n",
    "print(duplicates_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
